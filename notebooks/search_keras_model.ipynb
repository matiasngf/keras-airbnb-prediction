{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47238, 2479)\n",
      "(20996, 2479)\n",
      "(15747, 2479)\n"
     ]
    }
   ],
   "source": [
    "# loading data\n",
    "import importlib\n",
    "import load_transform_pipeline #import the module here, so that it can be reloaded.\n",
    "importlib.reload(load_transform_pipeline)\n",
    "import pickle\n",
    "file_path = '../models/data.pkl'\n",
    "data = pickle.load(open(file_path, 'rb'))\n",
    "\n",
    "X_train_df = data['X_train_df']\n",
    "X_test_df = data['X_test_df']\n",
    "X_val_df = data['X_val_df']\n",
    "\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "X_val = data['X_val']\n",
    "\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "y_val = data['y_val']\n",
    "\n",
    "transform_pipeline = data['transform_pipeline']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "# !pip install keras-tuner --user\n",
    "import kerastuner\n",
    "from kerastuner.tuners import RandomSearch, BayesianOptimization\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defino el build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(Dense(\n",
    "        hp.Int('input_units', min_value=256, max_value=2000, step=100),\n",
    "        input_shape=(X_train.shape[1],)\n",
    "    ))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    for i in range(hp.Int('num_layers', min_value=1, max_value=10, step=1)):\n",
    "        model.add(Dense(\n",
    "            hp.Int(f'layer_{i}_units', min_value=100, max_value=1200, step=100),\n",
    "        ))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Dropout(\n",
    "            hp.Float(f'layer_{i}_dropout', min_value=0, max_value=.5, step=.1)\n",
    "        ))\n",
    "\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(optimizer=optimizers.Adam(amsgrad=True), loss='mean_squared_error', metrics=['mae', r2_keras])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = os.path.join(\"..\",'models','BayesianOptimization',str(int(time.time())))\n",
    "\n",
    "tuner = BayesianOptimization(\n",
    "    build_model,\n",
    "    objective = 'val_loss',\n",
    "    max_trials = 2,\n",
    "    executions_per_trial = 1,\n",
    "    directory=LOG_DIR,\n",
    "    project_name='airbnb'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10, restore_best_weights=True, verbose=1)\n",
    "callbacks_list = [early_stopping, reduce_lr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47238 samples, validate on 15747 samples\n",
      "Epoch 1/300\n"
     ]
    }
   ],
   "source": [
    "tuner.search(\n",
    "    x=X_train.todense(),\n",
    "    y=y_train,\n",
    "    verbose=2, # just slapping this here bc jupyter notebook. The console out was getting messy.\n",
    "    epochs=300,\n",
    "    batch_size=64,\n",
    "    callbacks= callbacks_list,\n",
    "    validation_data=(X_val.todense(), y_val)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
