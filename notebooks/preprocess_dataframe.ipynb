{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_names = []\n",
    "path_df = '../datasets/original_files/'\n",
    "for (dirpath, dirnames, filenames) in walk(path_df):\n",
    "    datasets_names.extend(filenames)\n",
    "    break\n",
    "datasets_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataFrame = False\n",
    "first = True\n",
    "for name in datasets_names:\n",
    "    if(first):\n",
    "        first = False\n",
    "        dataFrame = pd.read_csv(path_df+name, compression='gzip')\n",
    "        dataFrame.set_index('id', drop=False, inplace=True)\n",
    "        print('adding', len(dataFrame), 'rows')\n",
    "    else:\n",
    "        _tmpDf = pd.read_csv(path_df+name, compression='gzip')\n",
    "        _tmpDf.set_index('id', drop=False, inplace=True)\n",
    "        print('adding', len(_tmpDf), 'rows')\n",
    "        dataFrame = pd.concat([dataFrame, _tmpDf])\n",
    "        del _tmpDf\n",
    "print('total rows:', len(dataFrame))\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cleaning columns\n",
    "for x in dataFrame.columns:\n",
    "    print(x)\n",
    "    values = dataFrame[x][pd.notna(dataFrame[x])].values\n",
    "    if(len(values) > 0):\n",
    "        print(values[0])\n",
    "    else:\n",
    "        print('NOT_VALUES')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbourhood\n",
    "# neighbourhood_cleansed\n",
    "# neighbourhood_group_cleansed\n",
    "# guests_included\n",
    "# license\n",
    "# is_business_travel_ready\n",
    "\n",
    "cols_to_drop = [\n",
    "    'market', 'street',\n",
    "    'listing_url', 'scrape_id', 'thumbnail_url', 'medium_url', 'picture_url', 'xl_picture_url', 'host_id', 'host_url',\n",
    "    'host_name', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood',\n",
    "    'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'zipcode', 'smart_location', 'country_code',\n",
    "    'weekly_price', 'monthly_price', 'security_deposit', 'cleaning_fee', 'extra_people',\n",
    "    'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights',\n",
    "    'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability',\n",
    "    'requires_license','jurisdiction_names','host_location'\n",
    "]\n",
    "# [colName for colName in dataFrame.columns if colName not in cols_to_drop]\n",
    "\n",
    "\n",
    "# dataFrame.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop outliers\n",
    "from scipy import stats\n",
    "dataFrame.loc[:,  'price'] = dataFrame.price.apply(lambda x: x[1:-3].replace(',', '')).astype(int)\n",
    "dataFrame = dataFrame[dataFrame.price!=0]\n",
    "dataFrame = dataFrame[(dataFrame.number_of_reviews>4)]\n",
    "dataFrame = dataFrame[(np.abs(stats.zscore(dataFrame[['price']])) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text pipeline steps\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "#Esta clase simplemente filtra las columnas que se le indica en el constructor\n",
    "class FeatureSelector( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self, feature_names ):\n",
    "        self._feature_names = feature_names \n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        return X[ self._feature_names ]\n",
    "    \n",
    "class TextTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __clean_text(self, x):\n",
    "        for punct in \"/-'\":\n",
    "            x = x.replace(punct, ' ')\n",
    "        for punct in '&':\n",
    "            x = x.replace(punct, f' {punct} ')\n",
    "        for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~•' + '“”’':\n",
    "            x = x.replace(punct, '')\n",
    "        return x.lower()\n",
    "    \n",
    "    def __parseTextCols(self, x):\n",
    "        finalTexts = []\n",
    "        for i in x:\n",
    "            if(pd.notna(i) and i not in finalTexts):\n",
    "                finalTexts.append(i)\n",
    "        text = self.__clean_text(' '.join(finalTexts))\n",
    "        return text\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform (self, X, y = None):\n",
    "        return X.apply(self.__parseTextCols, axis=1)\n",
    "    \n",
    "    \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "class custom_Tfidf(TfidfVectorizer, TransformerMixin):\n",
    "    options= {\n",
    "        'fitSample': 1\n",
    "    }\n",
    "    def __init__(self, params, options = None):\n",
    "        self.vectorizer = TfidfVectorizer(**params)\n",
    "        if(options != None):\n",
    "            for key in options.keys():\n",
    "                self.options[key] = options[key]\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        self.vectorizer.fit(X.sample(frac=self.options['fitSample']))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        return self.vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "text_cols = [\"name\",\"summary\",\"space\",\"description\",\"neighborhood_overview\",\"notes\",\"transit\",\"access\",\n",
    "             \"interaction\",\"house_rules\",\"host_about\"]\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_en = stopwords.words('english')\n",
    "textVectSettings = {\n",
    "    'stop_words': stopwords_en,\n",
    "    'max_df': 0.95,\n",
    "    'min_df': .05,\n",
    "    'ngram_range': (1,2),\n",
    "    'max_features': 300\n",
    "}\n",
    "\n",
    "#Pasos para el pipeline Textos\n",
    "text_pipeline = Pipeline(steps = [\n",
    "    ( 'text_selector', FeatureSelector(text_cols) ),\n",
    "    ( 'text_transformer', TextTransformer() ),\n",
    "    ( 'text_vectorize',  custom_Tfidf(textVectSettings, {'fitSample':1}))\n",
    "] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols = [\"instant_bookable\",\"is_business_travel_ready\",\"cancellation_policy\",\n",
    "\"require_guest_phone_verification\",\n",
    "\"require_guest_profile_picture\",\"host_response_time\",\n",
    "\"host_is_superhost\",\"host_has_profile_pic\",\"host_identity_verified\",\n",
    "\"city\",\"state\",\"property_type\",\"room_type\",\"bed_type\"];\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "dummy_pipeline = Pipeline(steps = [\n",
    "    ('dummy_selector', FeatureSelector(dummy_cols)),\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NumericalImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__( self, default_strategy = \"median\"):\n",
    "        self._default_strategy = default_strategy\n",
    "        self._default_values = {}\n",
    "        \n",
    "    def fit( self, X, y = None ):\n",
    "        X.host_response_rate = X.host_response_rate.str.replace('%', '').astype(float)\n",
    "        X.host_acceptance_rate = X.host_acceptance_rate.str.replace('%', '').astype(float)\n",
    "        \n",
    "        #Si hay valores infinitos los convertimos en NaN\n",
    "        X = X.replace( [ np.inf, -np.inf ], np.nan )\n",
    "        \n",
    "        for col in X.columns:\n",
    "            if col=='number_of_reviews_ltm':\n",
    "                default_value=0;\n",
    "            elif col=='number_of_reviews':\n",
    "                default_value=0;\n",
    "            elif col=='host_listings_count':\n",
    "                default_value=1;\n",
    "            elif self._default_strategy=='median':\n",
    "                default_value=np.median(X[col].dropna())\n",
    "            elif self._default_strategy=='mode':\n",
    "                default_value=np.mode(X[col].dropna())\n",
    "            elif self._default_strategy=='mean':\n",
    "                default_value=np.mean(X[col].dropna())\n",
    "            else:\n",
    "                default_value=np.median(X[col].dropna())\n",
    "            self._default_values[col]=default_value\n",
    "\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        X.host_response_rate = X.host_response_rate.astype(str).str.replace('%', '').astype(float)\n",
    "        X.host_acceptance_rate = X.host_acceptance_rate.astype(str).str.replace('%', '').astype(float)\n",
    "        \n",
    "        for col in X.columns:\n",
    "            X[col] = X[col].astype(float)\n",
    "            #Si hay valores infinitos los convertimos en NaN\n",
    "            X[col] = X[col].replace( [ np.inf, -np.inf ], np.nan)\n",
    "            X[col].fillna(self._default_values[col],inplace=True)\n",
    "        return X\n",
    "\n",
    "class NumericalTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__( self, log_transform = True):\n",
    "        self._log_transform = log_transform\n",
    "        \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        \n",
    "        if self._log_transform:\n",
    "            for col in X.columns:\n",
    "                colname = col+\"_log\"\n",
    "                X.loc[:,colname] = np.log(X[col]+1)\n",
    "                \n",
    "        #Retornamos un array de Numpy ?\n",
    "        return X\n",
    "    \n",
    "class NumericalAddFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__( self, bath_per_bed = True, bath_per_bedroom = True ):\n",
    "        self._bath_per_bed = bath_per_bed\n",
    "        self._bath_per_bedroom = bath_per_bedroom\n",
    "        \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        if self._bath_per_bedroom:\n",
    "            X.loc[X['bedrooms']==0,'bedrooms']=1;\n",
    "            X['bath_per_bedroom'] = X['bathrooms'] / X['bedrooms']\n",
    "        if self._bath_per_bed:\n",
    "            X.loc[X['beds']==0,'beds']=1;\n",
    "            X['bath_per_bed'] = X['bathrooms'] / X['beds']\n",
    "        \n",
    "        # ejemplo para clasificar valores\n",
    "        #pd.cut(df.Age,bins=[0,2,17,65,99],labels=['Toddler/Baby','Child','Adult','Elderly'])\n",
    "        \n",
    "        #Retornamos un array de Numpy ?\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuos_cols = [\n",
    "    \"reviews_per_month\",\"host_response_rate\",\"host_acceptance_rate\",\n",
    "    \"review_scores_communication\",\"review_scores_location\",\"review_scores_value\",\n",
    "    \"number_of_reviews_ltm\",\"review_scores_rating\",\"review_scores_cleanliness\",\n",
    "    \"review_scores_checkin\",\"availability_30\",\"availability_60\",\"availability_90\",\"availability_365\",\n",
    "    \"review_scores_accuracy\",\"minimum_nights\",\"maximum_nights\",\n",
    "    \"calculated_host_listings_count\",\"calculated_host_listings_count_entire_homes\",\n",
    "    \"calculated_host_listings_count_private_rooms\",\"calculated_host_listings_count_shared_rooms\",\n",
    "    \"host_listings_count\",\"number_of_reviews\",\n",
    "    \"accommodates\",\"bathrooms\",\"bedrooms\",\"beds\",\"guests_included\",\n",
    "]\n",
    "\n",
    "\n",
    "numerical_pipeline = Pipeline( steps = [\n",
    "    ( 'num_selector', FeatureSelector(continuos_cols) ),\n",
    "    ( 'num_imputer', NumericalImputer(default_strategy = 'median') ),\n",
    "    ( 'num_transformer', NumericalTransformer() ),\n",
    "    ( 'std_scaler', StandardScaler() ) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "full_pipeline = FeatureUnion( transformer_list = [ \n",
    "    ('numerical_pipeline', numerical_pipeline ),\n",
    "    ('dummy_pipeline', dummy_pipeline ),\n",
    "    ('text_pipeline', text_pipeline ),\n",
    "] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# y = dataFrame.price.apply(lambda x: x[1:-3].replace(',', '')).astype(int)\n",
    "y = dataFrame.price\n",
    "X = dataFrame.drop('price', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "# full_pipeline.fit(dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = full_pipeline.transform(X_train)\n",
    "train_targets = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = full_pipeline.transform(X_test)\n",
    "validation_targets = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "\n",
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Dense(1500, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1500, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1500, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1500, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1500, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(1000, input_shape=(train_data.shape[1],), kernel_regularizer=regularizers.l2(0.003)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.33))\n",
    "\n",
    "model.add(Dense(1000))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(800))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(700))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(600))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mean_squared_logarithmic_error', metrics=['mae', r2_keras])\n",
    "# mean_squared_logarithmic_error\n",
    "# mean_squared_error\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=4, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=20, restore_best_weights=True, verbose=1)\n",
    "callbacks_list = [early_stopping, reduce_lr]\n",
    "\n",
    "model.optimizer.learning_rate.assign(0.001)\n",
    "\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    train_targets,\n",
    "    epochs=100,\n",
    "    batch_size=512,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_split=.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('LOSS')\n",
    "plt.plot(epochs, loss)\n",
    "plt.ylim((0, .5))\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.xticks(ticks=epochs)\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training loss', 'Validation loss'])\n",
    "plt.show()\n",
    "\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('MAE')\n",
    "plt.plot(epochs, mae)\n",
    "plt.plot(epochs, val_mae)\n",
    "plt.xticks(ticks=epochs)\n",
    "plt.ylabel('Mae')\n",
    "plt.legend(['Training mae', 'Validation mae'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = history.history['r2_keras']\n",
    "val_acc = history.history['val_r2_keras']\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('R2')\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.xticks(ticks=epochs)\n",
    "plt.ylabel('R2')\n",
    "plt.ylim((.4, None))\n",
    "plt.legend(['Training r2', 'Validation r2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.hist(train_targets, bins=20, range=(0, 700))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.hist(validation_targets, bins=20, range=(0, 700))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history['val_r2_keras'][-1]\n",
    "# 66.35355\n",
    "# 66.218636\n",
    "# 59.322807\n",
    "# 65.16372\n",
    "# 68.29044\n",
    "# 50.142715\n",
    "\n",
    "# 0.6787062883377075\n",
    "# 0.6495150923728943\n",
    "# 0.6714338064193726\n",
    "# 0.6882"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(train_data)\n",
    "# y_predicted = np.exp(y_predicted_log)\n",
    "\n",
    "y_test_predicted = model.predict(validation_data)\n",
    "\n",
    "# validation_data = full_pipeline.transform(X_test)\n",
    "# validation_targets = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = (0, 500)\n",
    "alpha = .01\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(train_targets, y_predicted, alpha=alpha)\n",
    "plt.scatter(train_targets, train_targets, alpha=alpha)\n",
    "plt.xlabel('Valor real por noche')\n",
    "plt.ylabel('Valor predicho por noche')\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(validation_targets, y_test_predicted[:,0], alpha=alpha)\n",
    "plt.scatter(validation_targets, validation_targets, alpha=alpha)\n",
    "plt.xlabel('Valor real por noche')\n",
    "plt.ylabel('Valor predicho por noche')\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = X_train.copy()\n",
    "\n",
    "df_predicted.loc[:, 'price'] = train_targets\n",
    "df_predicted.loc[:, 'predicted'] = y_predicted[:,0]\n",
    "df_predicted.loc[:, 'pred_ratio'] = y_predicted[:,0] / train_targets\n",
    "\n",
    "df_predicted[df_predicted.price>1000][['price', 'predicted', 'pred_ratio', 'listing_url', 'name']].sort_values('pred_ratio')\n",
    "# df_predicted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
