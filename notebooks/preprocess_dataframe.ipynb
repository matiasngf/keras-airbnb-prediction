{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_names = []\n",
    "path_df = '../datasets/original_files/'\n",
    "for (dirpath, dirnames, filenames) in walk(path_df):\n",
    "    datasets_names.extend(filenames)\n",
    "    break\n",
    "datasets_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataFrame = False\n",
    "first = True\n",
    "for name in datasets_names:\n",
    "    if(first):\n",
    "        first = False\n",
    "        dataFrame = pd.read_csv(path_df+name, compression='gzip')\n",
    "        dataFrame.set_index('id', drop=False, inplace=True)\n",
    "        print(name,'adding', len(dataFrame), 'rows')\n",
    "    else:\n",
    "        _tmpDf = pd.read_csv(path_df+name, compression='gzip')\n",
    "        _tmpDf.set_index('id', drop=False, inplace=True)\n",
    "        print(name,'adding', len(_tmpDf), 'rows')\n",
    "        dataFrame = pd.concat([dataFrame, _tmpDf])\n",
    "        del _tmpDf\n",
    "print('total rows:', len(dataFrame))\n",
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorizando Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = [\"name\",\"summary\",\"space\",\"description\",\"neighborhood_overview\",\"notes\",\"transit\",\"access\",\n",
    "             \"interaction\",\"house_rules\",\"host_about\"];\n",
    "dummyable_cols = [\"instant_bookable\",\"is_business_travel_ready\",\"cancellation_policy\",\n",
    "                  \"require_guest_phone_verification\",\"requires_license\",\n",
    "                  \"require_guest_profile_picture\",\"host_location\",\"host_response_time\",\n",
    "                  \"host_is_superhost\",\"host_neighbourhood\",\"host_has_profile_pic\",\"host_identity_verified\",\n",
    "                  \"has_availability\",\"neighbourhood_cleansed\",\"city\",\"state\",\"market\",\n",
    "                  \"country_code\",\"property_type\",\"room_type\",\"bed_type\"];\n",
    "dropeable_cols = [\"id\",\"listing_url\",\"scrape_id\",\"last_scraped\",\"thumbnail_url\",\"medium_url\",\n",
    "                  \"picture_url\",\"xl_picture_url\",\"host_url\",\"host_name\",\"host_id\",\"host_thumbnail_url\",\n",
    "                 \"host_picture_url\",\"host_total_listings_count\",\"calendar_updated\",\"calendar_last_scraped\",\n",
    "                  \"neighbourhood\",\"neighbourhood_group_cleansed\",\"zipcode\",\"smart_location\",\"country\",\n",
    "                 \"experiences_offered\"];\n",
    "continuos_cols = [\"reviews_per_month\",\"host_response_rate\",\"host_acceptance_rate\",\n",
    "                  \"review_scores_communication\",\"review_scores_location\",\"review_scores_value\",\n",
    "                  \"number_of_reviews_ltm\",\"review_scores_rating\",\"review_scores_cleanliness\",\n",
    "                  \"review_scores_checkin\",\"availability_30\",\"availability_60\",\"availability_90\",\"availability_365\",\n",
    "                 \"review_scores_accuracy\",\"minimum_nights\",\"maximum_nights\",\"minimum_minimum_nights\",\n",
    "                  \"maximum_minimum_nights\",\"minimum_maximum_nights\",\"maximum_maximum_nights\",\n",
    "                  \"minimum_nights_avg_ntm\",\"maximum_nights_avg_ntm\",\n",
    "                  \"calculated_host_listings_count\",\"calculated_host_listings_count_entire_homes\",\n",
    "                  \"calculated_host_listings_count_private_rooms\",\"calculated_host_listings_count_shared_rooms\",\n",
    "                  \"host_listings_count\",\"number_of_reviews\",\n",
    "                  \"accommodates\",\"bathrooms\",\"bedrooms\",\"beds\",\"guests_included\",\n",
    "                  ]\n",
    "date_cols = [\"host_since\",\"first_review\",\"last_review\"]\n",
    "explotable_cols = [\"street\",\"host_verifications\",\"jurisdiction_names\",\"amenities\"]\n",
    "geo_cols = [\"latitude\",\"longitude\",\"is_location_exact\"]\n",
    "\n",
    "target_col = [\"price\",\"weekly_price\",\"monthly_price\",\"security_deposit\",\"cleaning_fee\",\"extra_people\"]\n",
    "#license ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataFrame.drop(text_cols,axis=1,inplace=True);\n",
    "#dataFrame.drop(dummyable_cols,axis=1,inplace=True);\n",
    "#dataFrame.drop(dropeable_cols,axis=1,inplace=True);\n",
    "#dataFrame.drop(continuos_cols,axis=1,inplace=True);\n",
    "#dataFrame.drop(date_cols,axis=1,inplace=True);\n",
    "#dataFrame.drop(explotable_cols,axis=1,inplace=True);\n",
    "#dataFrame.drop(geo_cols,axis=1,inplace=True);\n",
    "\n",
    "#dataFrame.drop(target_col,axis=1,inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplos de las columnas categorizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas detectadas como texto\n",
    "dataFrame.sample(5).loc[:,text_cols].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas detectadas como candidatas para hacer Dummies\n",
    "dataFrame.sample(5).loc[:,dummyable_cols].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas a ser dropeadas directamente\n",
    "dataFrame.sample(5).loc[:,dropeable_cols].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas detectadas como valores continuos, para reescalar\n",
    "dataFrame.sample(5).loc[:,continuos_cols].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Columnas detectadas como fecha \n",
    "dataFrame.sample(5).loc[:,date_cols].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas que habria que trabajar para separarles los datos\n",
    "dataFrame.sample(5).loc[:,explotable_cols].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas detectadas como informacion de geolocalizacion\n",
    "dataFrame.sample(5).loc[:,geo_cols].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columnas detectadas como que pueden filtrar informacion del target\n",
    "dataFrame.sample(5).loc[:,target_col].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test de modelado solo con Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop outliers\n",
    "dataFrame[\"price\"]=dataFrame[\"price\"].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "\n",
    "Q1 = dataFrame[\"price\"].quantile(0.02)\n",
    "Q3 = dataFrame[\"price\"].quantile(0.98)\n",
    "\n",
    "dataFrame.drop(dataFrame[dataFrame[\"price\"] > Q3].index,axis=0,inplace=True);\n",
    "dataFrame.drop(dataFrame[dataFrame[\"price\"] < Q1].index,axis=0,inplace=True);\n",
    "\n",
    "dataFrame[\"price\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# generamos las dummies y limpiamos el vector target\n",
    "X = pd.get_dummies(dataFrame[dummyable_cols].astype(str), drop_first=True).reset_index(drop=True)\n",
    "y = np.log(dataFrame[\"price\"].reset_index(drop=True));\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separamos entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, val_data, train_targets, val_targets = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(train_data.shape[1],),kernel_regularizer=regularizers.l1(0.001)))\n",
    "model.add(Dense(50, activation='relu',kernel_regularizer=regularizers.l1(0.001)))\n",
    "model.add(Dense(50, activation='relu',kernel_regularizer=regularizers.l1(0.001)))\n",
    "model.add(Dense(1,kernel_regularizer=regularizers.l1(0.001)))\n",
    "model.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['mae'])\n",
    "model.fit(train_data, train_targets,epochs=5, batch_size=500, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_data, val_targets, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspeccionamos los valores continuos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#revisamos una pequeña muestra de los datos\n",
    "dataFrame.sample(5).loc[:,continuos_cols].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1ro lo obvio -> son todos valores continuos.\n",
    "* 2do -> Se puede apreciar presencia de valores null.\n",
    "* 3ro -> Se vé que hay diferentes escalas de datos. Será conveniente reescalar y normalizar.\n",
    "* 4to -> Quizas sea favorable puede aplicar transformaciones para favorecer la predictibilidad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.loc[:,continuos_cols].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Acá se detectan 2 columnas que vienen con tipo de dato Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisis clasico\n",
    "dataFrame.loc[:,continuos_cols].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* se detectan varios campos con valores null, vamos a usar esto para intentar rellenarlo cuando sea posible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graficamos para ver interelacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
    "sns.pairplot(dataFrame.sample(1000).loc[:,continuos_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creamos los pasos del pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "#Esta clase simplemente filtra las columnas que se le indica en el constructor\n",
    "class FeatureSelector( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self, feature_names ):\n",
    "        self._feature_names = feature_names \n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        return X[ self._feature_names ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NumericalImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__( self, default_strategy = \"median\"):\n",
    "        self._default_strategy = default_strategy\n",
    "        self._default_values = {}\n",
    "        \n",
    "    def fit( self, X, y = None ):\n",
    "        X.host_response_rate = X.host_response_rate.str.replace('%', '').astype(float)\n",
    "        X.host_acceptance_rate = X.host_acceptance_rate.str.replace('%', '').astype(float)\n",
    "        \n",
    "        #Si hay valores infinitos los convertimos en NaN\n",
    "        X = X.replace( [ np.inf, -np.inf ], np.nan )\n",
    "        \n",
    "        for col in X.columns:\n",
    "            if col=='number_of_reviews_ltm':\n",
    "                default_value=0;\n",
    "            elif col=='number_of_reviews':\n",
    "                default_value=0;\n",
    "            elif col=='host_listings_count':\n",
    "                default_value=1;\n",
    "            elif self._default_strategy=='median':\n",
    "                default_value=np.median(X[col].dropna())\n",
    "            elif self._default_strategy=='mode':\n",
    "                default_value=np.mode(X[col].dropna())\n",
    "            elif self._default_strategy=='mean':\n",
    "                default_value=np.mean(X[col].dropna())\n",
    "            else:\n",
    "                default_value=np.median(X[col].dropna())\n",
    "            self._default_values[col]=default_value\n",
    "\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        X.host_response_rate = X.host_response_rate.astype(str).str.replace('%', '').astype(float)\n",
    "        X.host_acceptance_rate = X.host_acceptance_rate.astype(str).str.replace('%', '').astype(float)\n",
    "        \n",
    "        for col in X.columns:\n",
    "            #Si hay valores infinitos los convertimos en NaN\n",
    "            X[col] = X[col].replace( [ np.inf, -np.inf ], np.nan)\n",
    "            X[col].fillna(self._default_values[col],inplace=True)\n",
    "        return X\n",
    "\n",
    "class NumericalTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__( self, log_transform = True, bath_per_bed = True, bath_per_bedroom = True ):\n",
    "        self._bath_per_bed = bath_per_bed\n",
    "        self._bath_per_bedroom = bath_per_bedroom\n",
    "        self._log_transform = log_transform\n",
    "        \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        if self._bath_per_bedroom:\n",
    "            X.loc['bath_per_bedroom'] = X['bathrooms'] / X['bedrooms']\n",
    "        if self._bath_per_bed:\n",
    "            X.loc['bath_per_bed'] = X['bathrooms'] / X['beds']\n",
    "        if self._log_transform:\n",
    "            for col in X.columns:\n",
    "                X[col] = X[col];\n",
    "                #X[col] = np.log(X[col])\n",
    "        \n",
    "        #pd.cut(df.Age,bins=[0,2,17,65,99],labels=['Toddler/Baby','Child','Adult','Elderly'])\n",
    "        \n",
    "        #Retornamos un array de Numpy\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generamos los pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "#Definimos los pasos para el pipeline de Dummies\n",
    "#categorical_pipeline = Pipeline( steps = [ ( 'cat_selector', FeatureSelector(categorical_features) ),\n",
    "#                                  ( 'cat_transformer', CategoricalTransformer() ), \n",
    "#                                  ( 'one_hot_encoder', OneHotEncoder( sparse = False ) ) ] )\n",
    "    \n",
    "#Definimos los pasos para el pipeline Numerico\n",
    "numerical_pipeline = Pipeline( steps = [ ( 'num_selector', FeatureSelector(continuos_cols) ),\n",
    "                                  ( 'num_imputer', NumericalImputer(default_strategy = 'median') ),\n",
    "                                  ( 'num_transformer', NumericalTransformer() ),\n",
    "                                  ( 'std_scaler', StandardScaler() ) \n",
    "                                       ] )\n",
    "\n",
    "#Combinamos los diferentes pipelines en uno gran pipeline horizontal usando FeatureUnion\n",
    "full_pipeline = FeatureUnion( transformer_list = [ \n",
    "#                                                  ( 'categorical_pipeline', categorical_pipeline ), \n",
    "                                                  ( 'numerical_pipeline', numerical_pipeline ) ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline.fit(dataFrame);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame( full_pipeline.transform(dataFrame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
