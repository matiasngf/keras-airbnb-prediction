{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "import importlib\n",
    "import load_transform_pipeline #import the module here, so that it can be reloaded.\n",
    "importlib.reload(load_transform_pipeline)\n",
    "import pickle\n",
    "file_path = '../models/data.pkl'\n",
    "data = pickle.load(open(file_path, 'rb'))\n",
    "\n",
    "X_train_df = data['X_train_df']\n",
    "X_test_df = data['X_test_df']\n",
    "\n",
    "X_train = data['X_train']\n",
    "X_test = data['X_test']\n",
    "\n",
    "y_train = data['y_train']\n",
    "y_test = data['y_test']\n",
    "\n",
    "transform_pipeline = data['transform_pipeline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.layers import BatchNormalization, Activation\n",
    "\n",
    "def r2_keras(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Dense(1000, input_shape=(X_train.shape[1],), kernel_regularizer=regularizers.l2(0.003)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.33))\n",
    "\n",
    "model.add(Dense(1000))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(800))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(700))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(600))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mean_squared_logarithmic_error', metrics=['mae', r2_keras])\n",
    "# mean_squared_logarithmic_error\n",
    "# mean_squared_error\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=4, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=20, restore_best_weights=True, verbose=1)\n",
    "callbacks_list = [early_stopping, reduce_lr]\n",
    "\n",
    "model.optimizer.learning_rate.assign(0.001)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=100,\n",
    "    batch_size=512,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_split=.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('LOSS')\n",
    "plt.plot(epochs, loss)\n",
    "plt.ylim((0, .5))\n",
    "plt.plot(epochs, val_loss)\n",
    "plt.xticks(ticks=epochs)\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Training loss', 'Validation loss'])\n",
    "plt.show()\n",
    "\n",
    "mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('MAE')\n",
    "plt.plot(epochs, mae)\n",
    "plt.plot(epochs, val_mae)\n",
    "plt.xticks(ticks=epochs)\n",
    "plt.ylabel('Mae')\n",
    "plt.legend(['Training mae', 'Validation mae'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "acc = history.history['r2_keras']\n",
    "val_acc = history.history['val_r2_keras']\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.title('R2')\n",
    "plt.plot(epochs, acc)\n",
    "plt.plot(epochs, val_acc)\n",
    "plt.xticks(ticks=epochs)\n",
    "plt.ylabel('R2')\n",
    "plt.ylim((.4, None))\n",
    "plt.legend(['Training r2', 'Validation r2'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict(X_train)\n",
    "y_test_predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lims = (0, 500)\n",
    "alpha = .01\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(y_train, y_predicted, alpha=alpha)\n",
    "plt.scatter(y_train, y_train, alpha=alpha)\n",
    "plt.xlabel('Valor real por noche')\n",
    "plt.ylabel('Valor predicho por noche')\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(y_test, y_test_predicted[:,0], alpha=alpha)\n",
    "plt.scatter(y_test, y_test, alpha=alpha)\n",
    "plt.xlabel('Valor real por noche')\n",
    "plt.ylabel('Valor predicho por noche')\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted = X_train_df.copy()\n",
    "\n",
    "df_predicted.loc[:, 'price'] = y_train\n",
    "df_predicted.loc[:, 'predicted'] = y_predicted[:,0]\n",
    "df_predicted.loc[:, 'pred_ratio'] = y_predicted[:,0] / y_train\n",
    "\n",
    "df_predicted[df_predicted.price>1000][['price', 'predicted', 'pred_ratio', 'listing_url', 'name']].sort_values('pred_ratio')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
