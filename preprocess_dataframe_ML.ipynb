{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_names = []\n",
    "path_df = '../datasets/original_files/'\n",
    "for (dirpath, dirnames, filenames) in walk(path_df):\n",
    "    datasets_names.extend(filenames)\n",
    "    break\n",
    "datasets_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = False\n",
    "first = True\n",
    "for name in datasets_names:\n",
    "    if(first):\n",
    "        first = False\n",
    "        dataFrame = pd.read_csv(path_df+name, compression='gzip')\n",
    "        dataFrame.set_index('id', drop=False, inplace=True)\n",
    "        print('adding', len(dataFrame), 'rows')\n",
    "    else:\n",
    "        _tmpDf = pd.read_csv(path_df+name, compression='gzip')\n",
    "        _tmpDf.set_index('id', drop=False, inplace=True)\n",
    "        print('adding', len(_tmpDf), 'rows')\n",
    "        dataFrame = pd.concat([dataFrame, _tmpDf])\n",
    "        del _tmpDf\n",
    "print('total rows:', len(dataFrame))\n",
    "#dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dejar_solo_texto(cadena_): # funcion para estandarizar el texto en cada posicion del vector\n",
    "    \n",
    "    import nltk\n",
    "    from nltk.tokenize import RegexpTokenizer    \n",
    " \n",
    "    cadena = \"\".join(cadena_)\n",
    "    b = '}{@#$\"'                                         #Elimino carecteres especiales indicados enre ''\n",
    "    for char in b:\n",
    "        cadena = cadena.replace(char,\"\")\n",
    "\n",
    "    r_tokenizer=RegexpTokenizer(\"(?=\\w)[^,]+\")           \n",
    "    \n",
    "    x=r_tokenizer.tokenize(cadena)\n",
    "   \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_text(col):\n",
    "    \n",
    "    dataFrame[col]=dataFrame[col].apply(dejar_solo_texto)\n",
    "    dataFrame['amenities_clean']=dataFrame[col].apply(\" \".join)\n",
    "    dataFrame.drop(columns=[col])\n",
    "    \n",
    "    return dataFrame['amenities_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text('amenities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cleaning columns\n",
    "for x in dataFrame.columns:\n",
    "    print(x)\n",
    "    values = dataFrame[x][pd.notna(dataFrame[x])].values\n",
    "    if(len(values) > 0):\n",
    "        print(values[0])\n",
    "    else:\n",
    "        print('NOT_VALUES')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neighbourhood\n",
    "# neighbourhood_cleansed\n",
    "# neighbourhood_group_cleansed\n",
    "# guests_included\n",
    "# license\n",
    "# is_business_travel_ready\n",
    "\n",
    "cols_to_drop = [\n",
    "    'market', 'street',\n",
    "    'listing_url', 'scrape_id', 'thumbnail_url', 'medium_url', 'picture_url', 'xl_picture_url', 'host_id', 'host_url',\n",
    "    'host_name', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood',\n",
    "    'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'zipcode', 'smart_location', 'country_code',\n",
    "    'weekly_price', 'monthly_price', 'security_deposit', 'cleaning_fee', 'extra_people',\n",
    "    'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights',\n",
    "    'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability',\n",
    "    'requires_license','jurisdiction_names','host_location'\n",
    "]\n",
    "# [colName for colName in dataFrame.columns if colName not in cols_to_drop]\n",
    "\n",
    "\n",
    "# dataFrame.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop outliers\n",
    "from scipy import stats\n",
    "dataFrame.loc[:,  'price'] = dataFrame.price.apply(lambda x: x[1:-3].replace(',', '')).astype(int)\n",
    "dataFrame = dataFrame[dataFrame.price!=0]\n",
    "dataFrame = dataFrame[(dataFrame.number_of_reviews>2)]\n",
    "dataFrame = dataFrame[(np.abs(stats.zscore(dataFrame[['price']])) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text pipeline steps\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "#Esta clase simplemente filtra las columnas que se le indica en el constructor\n",
    "class FeatureSelector( BaseEstimator, TransformerMixin ):\n",
    "    #Class Constructor \n",
    "    def __init__( self, feature_names ):\n",
    "        self._feature_names = feature_names \n",
    "    \n",
    "    #Return self nothing else to do here    \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    #Method that describes what we need this transformer to do\n",
    "    def transform( self, X, y = None ):\n",
    "        return X[ self._feature_names ]\n",
    "    \n",
    "class TextTransformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __clean_text(self, x):\n",
    "        for punct in \"/-'\":\n",
    "            x = x.replace(punct, ' ')\n",
    "        for punct in '&':\n",
    "            x = x.replace(punct, f' {punct} ')\n",
    "        for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~•' + '“”’':\n",
    "            x = x.replace(punct, '')\n",
    "        return x.lower()\n",
    "    \n",
    "    def __parseTextCols(self, x):\n",
    "        finalTexts = []\n",
    "        for i in x:\n",
    "            if(pd.notna(i) and i not in finalTexts):\n",
    "                finalTexts.append(i)\n",
    "        text = self.__clean_text(' '.join(finalTexts))\n",
    "        return text\n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform (self, X, y = None):\n",
    "        return X.apply(self.__parseTextCols, axis=1)\n",
    "    \n",
    "    \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "class custom_Tfidf(TfidfVectorizer, TransformerMixin):\n",
    "    options= {\n",
    "        'fitSample': 1\n",
    "    }\n",
    "    def __init__(self, params, options = None):\n",
    "        self.vectorizer = TfidfVectorizer(**params)\n",
    "        if(options != None):\n",
    "            for key in options.keys():\n",
    "                self.options[key] = options[key]\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        self.vectorizer.fit(X.sample(frac=self.options['fitSample']))\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        return self.vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "text_cols = [\"name\",\"summary\",\"space\",\"description\",\"neighborhood_overview\",\"notes\",\"transit\",\"access\",\n",
    "             \"interaction\",\"house_rules\",\"host_about\",'amenities_clean']\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_en = stopwords.words('english')\n",
    "textVectSettings = {\n",
    "    'stop_words': stopwords_en,\n",
    "    'max_df': 0.95,\n",
    "    'min_df': .05,\n",
    "    'ngram_range': (1,2),\n",
    "    'max_features': 300\n",
    "}\n",
    "\n",
    "#Pasos para el pipeline Textos\n",
    "text_pipeline = Pipeline(steps = [\n",
    "    ( 'text_selector', FeatureSelector(text_cols) ),\n",
    "    ( 'text_transformer', TextTransformer() ),\n",
    "    ( 'text_vectorize',  custom_Tfidf(textVectSettings, {'fitSample':1}))\n",
    "] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols = [\"instant_bookable\",\"is_business_travel_ready\",\"cancellation_policy\",\n",
    "\"require_guest_phone_verification\",\n",
    "\"require_guest_profile_picture\",\"host_response_time\",\n",
    "\"host_is_superhost\",\"host_has_profile_pic\",\"host_identity_verified\",\n",
    "\"city\",\"state\",\"property_type\",\"room_type\",\"bed_type\"];\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "dummy_pipeline = Pipeline(steps = [\n",
    "    ('dummy_selector', FeatureSelector(dummy_cols)),\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NumericalImputer(BaseEstimator, TransformerMixin):\n",
    "    def __init__( self, default_strategy = \"median\"):\n",
    "        self._default_strategy = default_strategy\n",
    "        self._default_values = {}\n",
    "        \n",
    "    def fit( self, X, y = None ):\n",
    "        X.host_response_rate = X.host_response_rate.str.replace('%', '').astype(float)\n",
    "        X.host_acceptance_rate = X.host_acceptance_rate.str.replace('%', '').astype(float)\n",
    "        \n",
    "        #Si hay valores infinitos los convertimos en NaN\n",
    "        X = X.replace( [ np.inf, -np.inf ], np.nan )\n",
    "        \n",
    "        for col in X.columns:\n",
    "            if col=='number_of_reviews_ltm':\n",
    "                default_value=0;\n",
    "            elif col=='number_of_reviews':\n",
    "                default_value=0;\n",
    "            elif col=='host_listings_count':\n",
    "                default_value=1;\n",
    "            elif self._default_strategy=='median':\n",
    "                default_value=np.median(X[col].dropna())\n",
    "            elif self._default_strategy=='mode':\n",
    "                default_value=np.mode(X[col].dropna())\n",
    "            elif self._default_strategy=='mean':\n",
    "                default_value=np.mean(X[col].dropna())\n",
    "            else:\n",
    "                default_value=np.median(X[col].dropna())\n",
    "            self._default_values[col]=default_value\n",
    "\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        X.host_response_rate = X.host_response_rate.astype(str).str.replace('%', '').astype(float)\n",
    "        X.host_acceptance_rate = X.host_acceptance_rate.astype(str).str.replace('%', '').astype(float)\n",
    "        \n",
    "        for col in X.columns:\n",
    "            X[col] = X[col].astype(float)\n",
    "            #Si hay valores infinitos los convertimos en NaN\n",
    "            X[col] = X[col].replace( [ np.inf, -np.inf ], np.nan)\n",
    "            X[col].fillna(self._default_values[col],inplace=True)\n",
    "        return X\n",
    "\n",
    "class NumericalTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__( self, log_transform = True):\n",
    "        self._log_transform = log_transform\n",
    "        \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        \n",
    "        if self._log_transform:\n",
    "            for col in X.columns:\n",
    "                colname = col+\"_log\"\n",
    "                X.loc[:,colname] = np.log(X[col]+1)\n",
    "                \n",
    "        #Retornamos un array de Numpy ?\n",
    "        return X\n",
    "    \n",
    "class NumericalAddFeatures(BaseEstimator, TransformerMixin):\n",
    "    def __init__( self, bath_per_bed = True, bath_per_bedroom = True ):\n",
    "        self._bath_per_bed = bath_per_bed\n",
    "        self._bath_per_bedroom = bath_per_bedroom\n",
    "        \n",
    "    def fit( self, X, y = None ):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        if self._bath_per_bedroom:\n",
    "            X.loc[X['bedrooms']==0,'bedrooms']=1;\n",
    "            X['bath_per_bedroom'] = X['bathrooms'] / X['bedrooms']\n",
    "        if self._bath_per_bed:\n",
    "            X.loc[X['beds']==0,'beds']=1;\n",
    "            X['bath_per_bed'] = X['bathrooms'] / X['beds']\n",
    "        \n",
    "        # ejemplo para clasificar valores\n",
    "        #pd.cut(df.Age,bins=[0,2,17,65,99],labels=['Toddler/Baby','Child','Adult','Elderly'])\n",
    "        \n",
    "        #Retornamos un array de Numpy ?\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continuos_cols = [\n",
    "    \"reviews_per_month\",\"host_response_rate\",\"host_acceptance_rate\",\n",
    "    \"review_scores_communication\",\"review_scores_location\",\"review_scores_value\",\n",
    "    \"number_of_reviews_ltm\",\"review_scores_rating\",\"review_scores_cleanliness\",\n",
    "    \"review_scores_checkin\",\"availability_30\",\"availability_60\",\"availability_90\",\"availability_365\",\n",
    "    \"review_scores_accuracy\",\"minimum_nights\",\"maximum_nights\",\n",
    "    \"calculated_host_listings_count\",\"calculated_host_listings_count_entire_homes\",\n",
    "    \"calculated_host_listings_count_private_rooms\",\"calculated_host_listings_count_shared_rooms\",\n",
    "    \"host_listings_count\",\"number_of_reviews\",\n",
    "    \"accommodates\",\"bathrooms\",\"bedrooms\",\"beds\",\"guests_included\",\n",
    "]\n",
    "\n",
    "\n",
    "numerical_pipeline = Pipeline( steps = [\n",
    "    ( 'num_selector', FeatureSelector(continuos_cols) ),\n",
    "    ( 'num_imputer', NumericalImputer(default_strategy = 'median') ),\n",
    "    ( 'num_transformer', NumericalTransformer() ),\n",
    "    ( 'std_scaler', StandardScaler() ) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "full_pipeline = FeatureUnion( transformer_list = [ \n",
    "    ('numerical_pipeline', numerical_pipeline ),\n",
    "    ('dummy_pipeline', dummy_pipeline ),\n",
    "    ('text_pipeline', text_pipeline ),\n",
    "] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# y = dataFrame.price.apply(lambda x: x[1:-3].replace(',', '')).astype(int)\n",
    "y = dataFrame.price\n",
    "X = dataFrame.drop('price', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train.head()\n",
    "\n",
    "# full_pipeline.fit(dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = full_pipeline.transform(X_train)\n",
    "train_targets = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = np.log1p(full_pipeline.transform(X_test))\n",
    "validation_targets = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_r2_score(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'r2', r2_score(labels, preds), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'rf',\n",
    "    'objective': 'regression',\n",
    "    'metric': ['lgb_r2_score','l2','AUC'],\n",
    "    'learning_rate': 0.0005,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'bagging_freq': 10,\n",
    "    'verbose': 0,\n",
    "    \"max_depth\": 8,\n",
    "    \"num_leaves\": 128,  \n",
    "    \"max_bin\": 512,\n",
    "    \"num_iterations\": 1000,\n",
    "    \"n_estimators\": 300\n",
    "}\n",
    "gbm = lgb.LGBMRegressor(**hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.fit(train_data,train_targets ,\n",
    "        eval_set=[(validation_data, validation_targets)],\n",
    "        eval_metric='l1',\n",
    "        early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = gbm.predict(train_data, num_iteration=gbm.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The rmse of prediction for train is:', mean_squared_log_error(y_pred_train ,train_targets ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = gbm.predict(validation_data, num_iteration=gbm.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The rmse of prediction for test is:', mean_squared_log_error(y_pred_test ,validation_targets ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def r2_fit(x, y):\n",
    "       results = {}\n",
    "\n",
    "       correlation = numpy.corrcoef(x, y)[0,1]\n",
    "\n",
    "        # r-squared\n",
    "       results['R_2'] = correlation**2\n",
    "\n",
    "       return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The r-squared of prediction for train is:' ,r2_fit(y_pred_train ,train_targets ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The r-squared of prediction for test is:', r2_fit(y_pred_test ,validation_targets ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fuente\n",
    "https://medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc \n",
    "\n",
    "https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/loss-functions/mean-squared-logarithmic-error-(msle)\n",
    "\n",
    "https://iartificial.net/error-cuadratico-medio-para-regresion/\n",
    "\n",
    "http://mkhalusova.github.io/blog/2019/04/17/ml-model-evaluation-metrics-p3#rmsle   \n",
    "\n",
    "https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
